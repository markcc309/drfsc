{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"drfsc","text":"<p>An open-source library for a distributed randomised feature selection and classification algorithm.</p>"},{"location":"#contributors","title":"Contributors","text":"<p>Mark Chiu Chong</p>"},{"location":"#overview","title":"Overview","text":"<p><code>drfsc</code> is an open-source Python implementation of the Distributed Randomised Feature Selection algorithm for Classification problems (D-RFSC). Beside addressing some of the shortcomings of the conventional FS method, its good performance has previously been shown on a range of benchmark datasets. However, to date no Python implementation is available. <code>drfsc</code> offers an easy to use, parallelized probabilistic population-based feature selection scheme that is flexible and can be adapted to a wide range of binary classification problems and is particularly useful for large data problems where model interpretability and model explainability is of high importance. It provides modules for model fitting, evaluation, and visualization. Tutorial notebooks are provided to demonstrate the use of the package.</p>"},{"location":"#installation","title":"Installation","text":"<p>The easiest way to install is from PyPI: just use</p> <p><code>pip install drfsc</code></p> <p>To install from source: clone this git repo, enter the directory, and run</p> <p><code>python setup.py install</code></p>"},{"location":"#license","title":"License","text":"<p>We invite anyone interested to use and modify this code under a MIT license.</p>"},{"location":"#dependencies","title":"Dependencies","text":"<p><code>drfsc</code> depends on the following packages:</p> <ul> <li>numpy</li> <li>scipy</li> <li>pandas</li> <li>matplotlib</li> <li>scikit-learn</li> <li>statsmodels</li> </ul>"},{"location":"#references","title":"References","text":"<p>Brankovic, A., Falsone, A., Prandini, M., Piroddi, L. (2018). A feature selection and classification algorithm based on randomized extraction of model populations</p> <p>Brankovic, A., Piroddi, L. (2019). A distributed feature selection scheme with partial information sharing</p>"},{"location":"drfsc_api/","title":"Documentation for <code>DRFSC</code>","text":"<p>Distributed Randomised Feature Selection for Classification (DRFSC)</p>"},{"location":"drfsc_api/#src.drfsc.DRFSC.__init__","title":"<code>__init__(n_vbins=1, n_hbins=1, n_runs=1, redistribute_features=False, feature_sharing='all', k=0, output='single', metric='roc_auc', verbose=False, polynomial=1, preprocess=True, max_processes=None)</code>","text":"<p>Constructor for DRFSC class. Initialises the DRFSC class with the given parameters.</p> <p>Parameters:</p> Name Type Description Default <code>n_vbins</code> <code>int, optional</code> <p>Number of vertical partitions to create for the data. Defaults to 1.</p> <code>1</code> <code>n_hbins</code> <code>int, optional</code> <p>Number of horizontal partitions to create for the data. If output = 'ensemble', each hbin will converge to its own best model. Defaults to 1.</p> <code>1</code> <code>n_runs</code> <code>int, optional</code> <p>Number of feature-sharing iterations to perform. Larger numbers may yield better results, but also take longer. Defaults to 1.</p> <code>1</code> <code>redistribute_features</code> <code>bool, optional</code> <p>If True, the base features included in each bin will be shuffled at each feature-sharing iteration. Does not affect feature sharing. Defaults to False.</p> <code>False</code> <code>feature_sharing</code> <code>str, optional</code> <p>The method used to share features. Defaults to 'all'. Options (str): 'all', 'latest', 'top_k'. If feature_sharing = 'all', the entire history of best features from all sub-processes will be shared. If feature)sharing = 'latest', features from all sub-processes at the current iteration will be shared. If feature_sharing = 'top_k', the best k features will be shared.</p> <code>'all'</code> <code>k</code> <code>int, optional</code> <p>Number of best features to share. Only used if feature_sharing = 'top_k'. Defaults to 0.</p> <code>0</code> <code>output</code> <code>str, optional</code> <p>Output type desired. Options (str): 'single', 'ensemble'. If output = 'single', the best model from all sub-processes will be returned. If output = 'ensemble', the best model from each horizontal partition will be returned. If output = 'ensemb;e'. no features between different horizontal partitions will be created. Defaults to 'single'.</p> <code>'single'</code> <code>metric</code> <code>str, optional</code> <p>Evaluation metric used in the optimisation process. Options (str) : ['acc', 'roc_auc', 'weighted', 'avg_prec', 'f1', 'auprc']. Defaults to 'roc_auc'. For more information on the metrics, see the documentation for the sklearn.metrics module.</p> <code>'roc_auc'</code> <code>verbose</code> <code>bool, optional</code> <p>if True, prints extra information. Defaults to False.</p> <code>False</code> <code>polynomial</code> <code>int, optional</code> <p>degree of polynomial features to use. Defaults to 1.</p> <code>1</code> <code>preprocess</code> <code>bool, optional</code> <p>If True, will scale-data, create dummies for categorical variables, and create polynomial features based on passed <code>polynomial</code> parameter. If False, will only convert data to numpy arrays. Defaults to True.</p> <code>True</code> <code>max_processes</code> <code>int, optional</code> <p>Enforces maximum number of processes that can be generated. If None, will use all available cores. Defaults to None.</p> <code>None</code>"},{"location":"drfsc_api/#src.drfsc.DRFSC.get_rfsc_params","title":"<code>get_rfsc_params()</code>","text":"<p>Getter for RFSC parameters. Returns a dictionary of the current RFSC parameters</p>"},{"location":"drfsc_api/#src.drfsc.DRFSC.set_rfsc_params","title":"<code>set_rfsc_params(params)</code>","text":"<p>Setter for RFSC parameters. Updates the RFSC parameters with the given dictionary. Dictionary must be in the form of {parameter_name: parameter_value}.</p> <p>To view available parameters, see help(RFSC_base.init)</p>"},{"location":"drfsc_api/#src.drfsc.DRFSC.load_data","title":"<code>load_data(X_train, X_val, Y_train, Y_val, X_test=None, Y_test=None, polynomial=1, preprocess=True)</code>","text":"<p>Preprocesses the data in the required way for the DRFSC model. Can be used to load data into the model if it has not been loaded yet. Scales the data to [0,1] and creates polynomial expansion based on the passed 'polynomial' parameter. </p> <p>Parameters:</p> Name Type Description Default <code>X_train</code> <code>np.ndarray or pd.DataFrame </code> <p>Train set data</p> required <code>X_val</code> <code>np.ndarray or pd.DataFrame</code> <p>Validation set data</p> required <code>Y_train</code> <code>np.ndarray or pd.DataFrame</code> <p>Train set labels</p> required <code>Y_val</code> <code>np.ndarray or pd.DataFrame</code> <p>Validation set labels</p> required <code>X_test</code> <code>np.ndarray or pd.DataFrame, optional</code> <p>Test set data. Only required if postprocessing is required. Defaults to None.</p> <code>None</code> <code>Y_test</code> <code>np.ndarray or pd.DataFrame optional</code> <p>Test set labels. Only required if postprocessing is required. Defaults to None.</p> <code>None</code> <code>polynomial</code> <code>int, optional</code> <p>degree of polynomial features to use. Defaults to 1.</p> <code>1</code> <code>preprocess</code> <code>bool, optional</code> <p>If True, will scale-data, create dummies for categorical variables, and create polynomial features based on passed <code>polynomial</code> parameter. If False, will only convert data to numpy arrays. Defaults to True.</p> <code>True</code>"},{"location":"drfsc_api/#src.drfsc.DRFSC.load_data--returns","title":"Returns","text":"<p>X_train, X_val, Y_train, Y_val, X_test, Y_test : np.ndarray     Preprocessed data and labels</p>"},{"location":"drfsc_api/#src.drfsc.DRFSC.fit","title":"<code>fit(X_train, X_val, Y_train, Y_val)</code>","text":"<p>The main function for fitting the model. Returns the a single final model if output == 'single', else returns a model ensemble based on the number of horizontal partitions (n_hbins).</p> <p>Parameters:</p> Name Type Description Default <code>X_train</code> <code>np.ndarray or pd.DataFrame </code> <p>Train set data</p> required <code>X_val</code> <code>np.ndarray or pd.DataFrame</code> <p>Validation set data</p> required <code>Y_train</code> <code>np.ndarray or pd.DataFrame</code> <p>Train set labels</p> required <code>Y_val</code> <code>np.ndarray or pd.DataFrame</code> <p>Validation set labels</p> required"},{"location":"drfsc_api/#src.drfsc.DRFSC.score","title":"<code>score(X_test, Y_test, metric=None)</code>","text":"<p>Used to evaluate the final model on the test set.</p> <p>Parameters:</p> Name Type Description Default <code>X_test</code> <code>np.ndarray or pd.DataFrame</code> <p>Test set data</p> required <code>Y_test</code> <code>np.ndarray or pd.DataFrame or pd.Series</code> <p>Test set labels</p> required <code>metric</code> <code>str, optional</code> <p>Metric to use for evaluation. By default uses the metric specified in the constructor. Other options: ('acc', 'roc_auc', 'weighted', 'avg_prec', 'f1', 'auprc').</p> <code>None</code> <p>Returns:</p> Name Type Description <code>evaluation</code> <code>dict</code> <p>returns the score of the model based on the metric specified.</p>"},{"location":"drfsc_api/#src.drfsc.DRFSC.feature_importance","title":"<code>feature_importance()</code>","text":"<p>Creates a bar plot of the features of the model and their contribution to the final prediction.</p> <p>Returns:</p> Name Type Description <code>figure</code> <code>matplotlib figure</code> <p>hisogram of feature coefficients for features of the final model.</p>"},{"location":"drfsc_api/#src.drfsc.DRFSC.pos_neg_prediction","title":"<code>pos_neg_prediction(data_index=0, X_test=None)</code>","text":"<p>Creates a plot of the positive and negative parts of the prediction. Returned figure shows, for a given sample (indexed by data_index), the value of the coefficients and multiplies them by the feature values. These components of the prediction are then plotted.</p> <p>Parameters:</p> Name Type Description Default <code>data_index</code> <code>int</code> <p>Index of the data observation to be plotted. If X_test is not provided, then the index is relative to the provided training/validation data. If X_test is provided, then the index is relative to the provided test data. Default is 0.</p> <code>0</code> <code>X_test</code> <code>np.array or pd.DataFrame</code> <p>Test data to be used for prediction. If provided, then the index is relative to the provided test data. Default is None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>figure</code> <code>matplotlib.pyplot.figure</code> <p>output figure</p>"},{"location":"drfsc_api/#src.drfsc.DRFSC.single_prediction","title":"<code>single_prediction(data_index=0, X_test=None)</code>","text":"<p>Creates a plot of the single prediction of the final model. Figure shows for a given sample (indexed by data_index) the coefficients of the final model, weighted by the feature values for the indexed observation.</p> <p>Parameters:</p> Name Type Description Default <code>data_index</code> <code>int</code> <p>Index of the data observation to be plotted. If X_test is not provided, then the index is relative to the provided training/validation data. If X_test is provided, then the index is relative to the provided test data. Default is 0.</p> <code>0</code> <code>X_test</code> <code>np.array or pd.DataFrame</code> <p>Test data to be used for prediction. If provided, then the index is relative to the provided test data. Default is None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>figure</code> <code>matplotlib.pyplot.figure</code> <p>output figure</p>"},{"location":"rfsc_api/","title":"Documentation for <code>RFSC</code>","text":"<p>         Bases: <code>RFSC_base</code></p> <p>Implements RFSC algorithm based on parameters inherited from RFSC_base.</p> <p>tol_check </p> <p>Checks if maximum difference between mu vectors is below tolerance threshold.</p> <p>Parameters:</p> Name Type Description Default <code>mu_update</code> <code>np.ndarray</code> <p>mu at iteration t+1</p> required <code>mu</code> <code>np.ndarray</code> <p>mu at iteration t</p> required <code>tol</code> <code>float</code> <p>tolerance condition</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True max difference below tolerance, else False.</p> <p>select_model </p> <p>Selects final model based on features that are above the regressor inclusion probability (rip) threshold</p> <p>Parameters:</p> Name Type Description Default <code>mu</code> <code>np.ndarray</code> <p>current feature probability vector</p> required <code>rip_cutoff</code> <code>float</code> <p>regressor inclusion probability threshold</p> required <p>Returns:</p> Name Type Description <code>model_feats</code> <code>list</code> <p>list of features that are above the rip threshold</p> <p>gamma_update </p> <p>Scale the update of the feature probability vector.</p> <p>Parameters:</p> Name Type Description Default <code>performance</code> <code>np.ndarray</code> <p>performance evaluation for each model.</p> required <code>tuning</code> <code>float, optional</code> <p>tuning parameter to adjust convergence rate, default=10</p> <code>10</code> <p>Returns:</p> Name Type Description <code>gamma</code> <code>float</code> <p>Scaling factor for the update of the feature probability vector</p> <p>generate_model </p> <p>Takes a vector of probabilities and returns a random model.</p> <p>Parameters:</p> Name Type Description Default <code>mu</code> <code>np.ndarray</code> <p>array of probabilities for each feature</p> required <p>Returns:</p> Name Type Description <code>index</code> <code>np.ndarray</code> <p>randomly generated numbers corresponding to features ids based on probabilities.</p> <p>prune_model </p> <p>Tests whether features are signifincant at selected signifincance level. Returns index of significant features.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>object</code> <p>logistic regression model object. See statsmodels.api.Logit</p> required <code>feature_ids</code> <code>list</code> <p>feature ids included in the model.</p> required <code>alpha</code> <code>float</code> <p>(0,1) significance level.</p> required <p>Returns:</p> Name Type Description <code>sig_feature_ids</code> <code>list</code> <p>list of features above the significance level.</p>"},{"location":"rfsc_api/#src.rfsc.RFSC.__init__","title":"<code>__init__(*args)</code>","text":"<p>Inherits parameters from RFSC_base. See help(RFSC_base.init) for more information.</p>"},{"location":"rfsc_api/#src.rfsc.RFSC.set_attr","title":"<code>set_attr(params)</code>","text":"<p>Setter for RFSC attributes. Used to update RFSC parameters for DRFSC model.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>dict</code> <p>Dictionary of parameters to update.</p> required"},{"location":"rfsc_api/#src.rfsc.RFSC.load_data_rfsc","title":"<code>load_data_rfsc(X_train, X_val, Y_train, Y_val, feature_partition=None, sample_partition=None, drfsc_index=None, M=None)</code>","text":"<p>Loads the data passed from DRFSC into the RFSC object.</p> <p>Parameters:</p> Name Type Description Default <code>X_train</code> <code>np.ndarray</code> <p>Training set data</p> required <code>X_val</code> <code>np.ndarray</code> <p>Validation set data</p> required <code>Y_train</code> <code>np.ndarray</code> <p>Training set labels</p> required <code>Y_val</code> <code>np.ndarray</code> <p>Validation set labels</p> required <code>feature_partition</code> <code>list</code> <p>list of features indices for corresponding drfsc index</p> <code>None</code> <code>sample_partition</code> <code>list</code> <p>list of sample indices for corresponding drfsc index</p> <code>None</code> <code>drfsc_index</code> <code>tupl</code> <p>index of DRFSC bin of the form (r,i,j), where r is the drfsc iteration number, i is the vertical partition index, and j is the horizontal partition index</p> <code>None</code> <code>M</code> <code>dict</code> <p>dictionary containing relevant previous information for feature sharing</p> <code>None</code>"},{"location":"rfsc_api/#src.rfsc.RFSC.rfsc_main","title":"<code>rfsc_main(X_train, X_val, Y_train, Y_val, drfsc_index=None)</code>","text":"<p>This is the main section of the RFSC algorithm called by DRFSC. It extracts the model populations and evaluates them on the validation set, and updates the feature inclusion probabilities accordingly.</p> <p>Parameters:</p> Name Type Description Default <code>X_train</code> <code>np.ndarray</code> <p>Training set data</p> required <code>X_val</code> <code>np.ndarray</code> <p>Validation set data</p> required <code>Y_train</code> <code>np.ndarray</code> <p>Training set labels</p> required <code>Y_val</code> <code>np.ndarray</code> <p>Validation set labels</p> required <code>drfsc_index</code> <code>tuple, optional</code> <p>index of DRFSC bin of the form (r,i,j), where r is the drfsc iteration number, i is the vertical partition index, and j is the horizontal partition index</p> <code>None</code>"},{"location":"rfsc_api/#src.rfsc.RFSC.generate_models","title":"<code>generate_models(X_train, Y_train, X_val, Y_val, mu)</code>","text":"<p>Generates random models and for each model evaluates the significance of each feature. Statistically significant features are retained and resultant model is regressed again and its performance on validation partition is evaluated and stored.</p> <p>Parameters:</p> Name Type Description Default <code>X_train</code> <code>np.ndarray</code> <p>Training data.</p> required <code>Y_train</code> <code>np.ndarray</code> <p>Training labels</p> required <code>X_val</code> <code>np.ndarray</code> <p>Validation data</p> required <code>Y_val</code> <code>np.ndarray</code> <p>Validation labels</p> required <code>mu</code> <code>np.ndarray</code> <p>Array of regressor inclusion probabilities of each feature.</p> required <p>Returns:</p> Name Type Description <code>mask_mtx</code> <code>np.ndarray</code> <p>Matrix containing 1 in row i at column j if feature j was included in model i, else 0.</p> <code>performance_vector</code> <code>np.ndarray</code> <p>Array containing performance of each model.</p> <code>size_vector</code> <code>np.ndarray</code> <p>Array containing number of features in each model.</p>"},{"location":"rfsc_api/#src.rfsc.RFSC.update_feature_probability","title":"<code>update_feature_probability(mask, performance, mu)</code>","text":"<p>Updates the feature probability vector mu based on the performance of the models generated.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>np.ndarray</code> <p>Matrix of shape (n_models, n_features) containing the mask of the models generated.</p> required <code>performance</code> <code>np.ndarray</code> <p>Performance evaluation for each model.</p> required <code>mu</code> <code>np.ndarray</code> <p>Current feature probability vector.</p> required <p>Returns:</p> Name Type Description <code>mu_update</code> <code>np.ndarray</code> <p>Updated feature probability vector.</p>"},{"location":"rfsc_base_api/","title":"Documentation for <code>RFSC_base</code>","text":"<p>Base class for RFSC. Used to update RFSC parameters for DRFSC model</p>"},{"location":"rfsc_base_api/#src.rfsc.RFSC_base.__init__","title":"<code>__init__(n_models=300, n_iters=150, tuning=50, tol=0.002, alpha=0.99, rip_cutoff=1, metric='roc_auc', verbose=False, upweight=1)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>n_models</code> <code>int</code> <p>Number of models generated per iteration. Default=300.</p> <code>300</code> <code>n_iters</code> <code>int</code> <p>Number of iterations. Default is 150.</p> <code>150</code> <code>tuning</code> <code>float</code> <p>Learning rate that dictates the speed of regressor inclusion probability (rip) convergence. Smaller values -&gt; slower convergence. Default is 50.</p> <code>50</code> <code>tol</code> <code>float</code> <p>Tolerance condition. Default is 0.002.</p> <code>0.002</code> <code>alpha</code> <code>float</code> <p>Significance level for model pruning. Default is 0.99.</p> <code>0.99</code> <code>rip_cutoff</code> <code>float</code> <p>Determines rip threshold for feature inclusion in final model. Default=1.</p> <code>1</code> <code>metric</code> <code>str</code> <p>Optimization metric. Default='roc_auc'. Options: 'acc', 'roc_auc', 'weighted', 'avg_prec', 'f1', 'auprc'.</p> <code>'roc_auc'</code> <code>verbose</code> <code>bool</code> <p>Provides extra information. Defaults is False.</p> <code>False</code> <code>upweight</code> <code>float</code> <p>Upweights initial feature rips. Default is 1.</p> <code>1</code>"},{"location":"utils/","title":"Documentation for <code>utils.py</code>","text":"<p>create_balanced_distributions </p> <p>Combines outputs from vertical_distribution and balanced_horizontal_partition to create class-balanced vertical and horizontal partitions for the dataset.</p> <p>balanced_horizontal_partition </p> <p>Creates class-balanced horizontal partitions for the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>np.ndarray</code> <p>data labels.</p> required <code>n_hbins</code> <code>int</code> <p>number of horizontal partiions of the data.</p> required <p>Returns:</p> Name Type Description <code>horizontal_partitions</code> <code>np.ndarray</code> <p>Class balanced version of horizontal_distribution.</p> <p>horizontal_distribution </p> <p>Creates horizontal bins for the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>n_samples</code> <code>int</code> <p>number of samples in the data.</p> required <code>n_hbins</code> <code>int</code> <p>number of horizontal partiions of the data.</p> required <p>Returns:</p> Name Type Description <code>horizontal_partitions</code> <code>np.ndarray</code> <p>Contains in each column the sample indexes of the samples that belong to that horizontal bin.</p> <p>vertical_distribution </p> <p>Function that creates vertical bins for the features in the dataset for use by DRFSC.</p> <p>Parameters:</p> Name Type Description Default <code>n_feats</code> <code>int</code> <p>number of features in the data</p> required <code>n_vbins</code> <code>int</code> <p>number of vertical partitions of the data.</p> required <p>Returns:</p> Name Type Description <code>vertical_partitions</code> <code>np.ndarray</code> <p>Contains in each column the features that belong to that vertical bin</p> <p>scale_data </p> <p>Uses sklearn.preprocessing to rescale feature values to [0,1].</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>np.ndarray or pd.DataFrame</code> <p>data to be transformed</p> required <p>Returns:</p> Name Type Description <code>data_out</code> <code>np.ndarray or pd.DataFrame</code> <p>[0,1] transform of data</p> <p>extend_features </p> <p>Uses sklearn.preprocessing to create polynomial features of data and add bias term.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>np.ndarray or pd.DataFrame</code> <p>data to be transformed</p> required <code>degree</code> <code>int, optional</code> <p>Degree of non-linearity to generate. Defaults to 1. By default just adds a bias term.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>data_out</code> <code>np.ndarray or pd.DataFrame</code> <p>Polynomial transformed data</p> <p>evaluate_model </p> <p>Evaluates the performance of a model on the test set.</p> <p>Parameters:</p> Name Type Description Default <code>model_features</code> <code>list</code> <p>Subset of features to be included in the model</p> required <code>X_train</code> <code>np.ndarray</code> <p>Training data</p> required <code>X_val</code> <code>np.ndarray</code> <p>Validation data</p> required <code>Y_train</code> <code>np.ndarray</code> <p>Training labels</p> required <code>Y_val</code> <code>np.ndarray</code> <p>Validation labels</p> required <code>metric</code> <code>str</code> <p>metric used to evaluate model performance</p> required <p>Returns:</p> Name Type Description <code>model_final</code> <code>object</code> <p>Fitted logistic regression model. See statsmodels.Logit</p> <code>model_performance</code> <code>float</code> <p>Performance of the model on the validation set</p> <p>evaluate_interim_model </p> <p>Evaluates the performance of a model on the validation set.</p> <p>Parameters:</p> Name Type Description Default <code>model_features</code> <code>list</code> <p>Subset of features to be included in the model</p> required <code>X_train</code> <code>np.ndarray</code> <p>Training data</p> required <code>X_val</code> <code>np.ndarray</code> <p>Validation data</p> required <code>Y_train</code> <code>np.ndarray</code> <p>Training labels</p> required <code>Y_val</code> <code>np.ndarray</code> <p>Validation labels</p> required <code>metric</code> <code>str</code> <p>metric used to evaluate model performance</p> required <p>Returns:</p> Name Type Description <code>model_final</code> <code>object</code> <p>Fitted logistic regression model. See statsmodels.Logit</p> <code>model_performance</code> <code>float</code> <p>Performance of the model on the validation set</p> <p>model_score </p> <p>Evalutates model performance based on specified metric using sklearn.metrics.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>metric used to evaluate model performance</p> required <code>y_true</code> <code>np.ndarray</code> <p>{0,1} ground truth labels</p> required <code>y_pred_label</code> <code>np.ndarray</code> <p>{0,1} predicted labels</p> required <code>y_pred_prob</code> <code>np.ndarray</code> <p>[0,1] predicted probabilities</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>float</code> <p>output based on metric</p>"}]}